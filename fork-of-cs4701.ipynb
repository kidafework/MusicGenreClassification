{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6813410,"sourceType":"datasetVersion","datasetId":3919378},{"sourceId":6899105,"sourceType":"datasetVersion","datasetId":3963030}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn as skl\nimport librosa\nimport librosa.display\nimport ast\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom sklearn import svm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        \n#code taken from MDEFF-FMA GitHub page for fetching metadata and audio files for FMA dataset.\n# (link: https://github.com/mdeff/fma/blob/master/utils.py)        \ndef load(filepath):\n\n    filename = os.path.basename(filepath)\n\n    if 'features' in filename:\n        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n\n    if 'echonest' in filename:\n        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n\n    if 'genres' in filename:\n        return pd.read_csv(filepath, index_col=0)\n\n    if 'tracks' in filename:\n        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n\n        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n                   ('track', 'genres'), ('track', 'genres_all')]\n        for column in COLUMNS:\n            tracks[column] = tracks[column].map(ast.literal_eval)\n\n        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n                   ('album', 'date_created'), ('album', 'date_released'),\n                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n                   ('artist', 'active_year_end')]\n        for column in COLUMNS:\n            tracks[column] = pd.to_datetime(tracks[column])\n\n        SUBSETS = ('small', 'medium', 'large')\n        try:\n            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n                    'category', categories=SUBSETS, ordered=True)\n        except (ValueError, TypeError):\n            # the categories and ordered arguments were removed in pandas 0.25\n            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n                     pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n\n        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n                   ('album', 'type'), ('album', 'information'),\n                   ('artist', 'bio')]\n        for column in COLUMNS:\n            tracks[column] = tracks[column].astype('category')\n\n        return tracks\n\n\n#code taken from MDEFF-FMA GitHub page for fetching metadata and audio files for FMA dataset.\n# (link: https://github.com/mdeff/fma/blob/master/utils.py)       \ndef get_audio_path(audio_dir, track_id):\n    \"\"\"\n    Return the path to the mp3 given the directory where the audio is stored\n    and the track ID.\n\n    Examples\n    --------\n    >>> import utils\n    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n    >>> utils.get_audio_path(AUDIO_DIR, 2)\n    '../data/fma_small/000/000002.mp3'\n\n    \"\"\"\n    tid_str = '{:06d}'.format(track_id)\n    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T14:38:35.110742Z","iopub.execute_input":"2023-12-14T14:38:35.111335Z","iopub.status.idle":"2023-12-14T14:38:51.337048Z","shell.execute_reply.started":"2023-12-14T14:38:35.111302Z","shell.execute_reply":"2023-12-14T14:38:51.335878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load and re-format pandas dataframe of metadata\ntracks = load(\"/kaggle/input/fma-metadata/fma_metadata/tracks.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:38:54.816731Z","iopub.execute_input":"2023-12-14T14:38:54.817901Z","iopub.status.idle":"2023-12-14T14:39:09.732934Z","shell.execute_reply.started":"2023-12-14T14:38:54.817862Z","shell.execute_reply":"2023-12-14T14:39:09.731896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tracks['track', 'genre_top'])","metadata":{"execution":{"iopub.status.busy":"2023-12-12T19:30:37.466717Z","iopub.execute_input":"2023-12-12T19:30:37.467064Z","iopub.status.idle":"2023-12-12T19:30:37.475429Z","shell.execute_reply.started":"2023-12-12T19:30:37.467035Z","shell.execute_reply":"2023-12-12T19:30:37.474487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop any tracks with inconsistencies\ntracks = tracks.drop(index=[98565,98567,98569,99134,108925,133297])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:09.734435Z","iopub.execute_input":"2023-12-14T14:39:09.734733Z","iopub.status.idle":"2023-12-14T14:39:09.805165Z","shell.execute_reply.started":"2023-12-14T14:39:09.734707Z","shell.execute_reply":"2023-12-14T14:39:09.804463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dictionary: mapping each genre to a unique int\nlabel_dict = {\"Hip-Hop\": 0, \"Rock\":1, \"Electronic\":2, \"Folk\": 3, \"Instrumental\":4, \"Pop\":5, \"International\":6, \"Experimental\":7}\n\nsmall = tracks[tracks['set','subset'] == 'small']\n\n# We set new_val to be the validation data set\nsmall_val = small[small['set','split'] == \"validation\"]\nnew_val = small_val.sample(n=500, random_state=1)\n\n#Set new_train to be the training data set\nsmall_train = small[small['set','split'] == 'training']\nnew_train = small_train.sample(n=4000, random_state=1)\n\n#Set new_test to be the testing data set\nsmall_test = small[small['set','split'] == 'test']\nnew_test = small_test.sample(n=500, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:17.895516Z","iopub.execute_input":"2023-12-14T14:39:17.895889Z","iopub.status.idle":"2023-12-14T14:39:17.937270Z","shell.execute_reply.started":"2023-12-14T14:39:17.895858Z","shell.execute_reply":"2023-12-14T14:39:17.936449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#examining list of possible genres in dataset\nlabels = set(small_train['track', 'genre_top'])\nlabel_list = list(labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:18.268365Z","iopub.execute_input":"2023-12-14T14:39:18.268736Z","iopub.status.idle":"2023-12-14T14:39:18.273672Z","shell.execute_reply.started":"2023-12-14T14:39:18.268703Z","shell.execute_reply":"2023-12-14T14:39:18.272815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Note that we are only using 5000 of the 8000 tracks in the dataset, due to Kaggle memory limitations.","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:11:49.18694Z","iopub.execute_input":"2023-11-04T13:11:49.187291Z","iopub.status.idle":"2023-11-04T13:11:49.192433Z","shell.execute_reply.started":"2023-11-04T13:11:49.187263Z","shell.execute_reply":"2023-11-04T13:11:49.191057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function that encodes top genres into number-labels\ndef label_encode(label):\n    if label in label_list:\n        return label_list.index(label)\n    else:\n        return -1","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:21.769235Z","iopub.execute_input":"2023-12-14T14:39:21.769866Z","iopub.status.idle":"2023-12-14T14:39:21.774320Z","shell.execute_reply.started":"2023-12-14T14:39:21.769833Z","shell.execute_reply":"2023-12-14T14:39:21.773508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#encoding genres into number-labels for training, validation, and testing subsets\nnew_train['track', 'genre_top'] = new_train['track', 'genre_top'].apply(label_encode)\nnew_test['track', 'genre_top'] = new_test['track', 'genre_top'].apply(label_encode)\nnew_val['track', 'genre_top'] = new_val['track', 'genre_top'].apply(label_encode)\n\n\n#print(new_train['track','genre_top'])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:23.412070Z","iopub.execute_input":"2023-12-14T14:39:23.412753Z","iopub.status.idle":"2023-12-14T14:39:23.421003Z","shell.execute_reply.started":"2023-12-14T14:39:23.412720Z","shell.execute_reply":"2023-12-14T14:39:23.420186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extract labels for dataset\ntrain_labels = np.array(new_train['track', 'genre_top'])\ntest_labels = np.array(new_test['track', 'genre_top'])\nval_labels = np.array(new_val['track', 'genre_top'])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:24.123550Z","iopub.execute_input":"2023-12-14T14:39:24.124229Z","iopub.status.idle":"2023-12-14T14:39:24.130034Z","shell.execute_reply.started":"2023-12-14T14:39:24.124190Z","shell.execute_reply":"2023-12-14T14:39:24.128918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"small_train['track', 'genre_top]","metadata":{}},{"cell_type":"code","source":"print(train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:30:46.388819Z","iopub.execute_input":"2023-12-09T22:30:46.389187Z","iopub.status.idle":"2023-12-09T22:30:46.397106Z","shell.execute_reply.started":"2023-12-09T22:30:46.389161Z","shell.execute_reply":"2023-12-09T22:30:46.396245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_track_ids = np.array(new_train.index)\nval_track_ids = np.array(new_val.index)\ntest_track_ids = np.array(new_test.index)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:26.880593Z","iopub.execute_input":"2023-12-14T14:39:26.881193Z","iopub.status.idle":"2023-12-14T14:39:26.885696Z","shell.execute_reply.started":"2023-12-14T14:39:26.881163Z","shell.execute_reply":"2023-12-14T14:39:26.884842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#omitted (removed) STFT feature extraction","metadata":{"execution":{"iopub.status.busy":"2023-12-09T20:16:30.699465Z","iopub.execute_input":"2023-12-09T20:16:30.699849Z","iopub.status.idle":"2023-12-09T20:47:55.513923Z","shell.execute_reply.started":"2023-12-09T20:16:30.699820Z","shell.execute_reply":"2023-12-09T20:47:55.512969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-12-09T20:56:19.071207Z","iopub.execute_input":"2023-12-09T20:56:19.071967Z","iopub.status.idle":"2023-12-09T20:56:35.321875Z","shell.execute_reply.started":"2023-12-09T20:56:19.071935Z","shell.execute_reply":"2023-12-09T20:56:35.320514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chrom_train = np.empty([1,12, 1293])\nchrom_val = np.empty([1,12, 1293])\nchrom_test = np.empty([1,12, 1293])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:29.346752Z","iopub.execute_input":"2023-12-14T14:39:29.347730Z","iopub.status.idle":"2023-12-14T14:39:29.352732Z","shell.execute_reply.started":"2023-12-14T14:39:29.347681Z","shell.execute_reply":"2023-12-14T14:39:29.351710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Chromagram feature extraction\ndef chroma_extraction(X,track_ids):\n    for i in track_ids:\n        filepath = get_audio_path('/kaggle/input/fma-audio/fma_small', i)\n        x, sr = librosa.load(filepath)\n        chrom = librosa.feature.chroma_stft(y=x, sr=sr)\n        a, b = chrom.shape\n        #padding the feature arrays to make sure all arrays are the same size\n        if (b < 1293):\n            if (1293 - b) % 2 == 0:\n                chrom = np.pad(chrom, ((0,0),(int((1293-b)/2),int((1293-b)/2))), 'edge')\n            else:\n                chrom = np.pad(chrom, ((0,0),(int((1293-b)/2),int((1293-b)/2)+1)), 'edge')\n        X = np.append(X, [chrom], axis = 0)\n    return X\n\n\n#chromagram feature extraction\nchrom_train = chroma_extraction(chrom_train,train_track_ids)\nchrom_val = chroma_extraction(chrom_val,val_track_ids)\nchrom_test = chroma_extraction(chrom_test,test_track_ids)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T14:39:30.156872Z","iopub.execute_input":"2023-12-14T14:39:30.157456Z","iopub.status.idle":"2023-12-14T15:03:08.572182Z","shell.execute_reply.started":"2023-12-14T14:39:30.157416Z","shell.execute_reply":"2023-12-14T15:03:08.570687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-12-10T23:15:05.408189Z","iopub.execute_input":"2023-12-10T23:15:05.408559Z","iopub.status.idle":"2023-12-10T23:15:05.415192Z","shell.execute_reply.started":"2023-12-10T23:15:05.408519Z","shell.execute_reply":"2023-12-10T23:15:05.414021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the first feature array in each data subset is an extra \"arbitrary\" feature array \n# We remove this extra feature array here\nchrom_train = np.delete(chrom_train, 0, 0)\nchrom_val = np.delete(chrom_val, 0, 0)\nchrom_test = np.delete(chrom_test, 0, 0)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:03:08.574147Z","iopub.execute_input":"2023-12-14T15:03:08.578628Z","iopub.status.idle":"2023-12-14T15:03:08.827647Z","shell.execute_reply.started":"2023-12-14T15:03:08.578589Z","shell.execute_reply":"2023-12-14T15:03:08.826846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chrom_train","metadata":{"execution":{"iopub.status.busy":"2023-12-13T07:39:30.320270Z","iopub.execute_input":"2023-12-13T07:39:30.320642Z","iopub.status.idle":"2023-12-13T07:39:30.324934Z","shell.execute_reply.started":"2023-12-13T07:39:30.320612Z","shell.execute_reply":"2023-12-13T07:39:30.324084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"chrom_train","metadata":{"execution":{"iopub.status.busy":"2023-12-08T09:11:22.669613Z","iopub.execute_input":"2023-12-08T09:11:22.670069Z","iopub.status.idle":"2023-12-08T09:11:22.716566Z","shell.execute_reply.started":"2023-12-08T09:11:22.670032Z","shell.execute_reply":"2023-12-08T09:11:22.715053Z"}}},{"cell_type":"code","source":"# Additionally, we have to remove all possible nan values in the dataset\n#chrom_train = np.nan_to_num(chrom_train)\n#chrom_val = np.nan_to_num(chrom_val)\n#chrom_test = np.nan_to_num(chrom_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:53:08.253351Z","iopub.execute_input":"2023-12-07T11:53:08.253764Z","iopub.status.idle":"2023-12-07T11:53:08.361501Z","shell.execute_reply.started":"2023-12-07T11:53:08.253737Z","shell.execute_reply":"2023-12-07T11:53:08.360521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set-up a CNN model\n#data_augment = tf.keras.Sequential([\n#  tf.keras.layers.RandomFlip('horizontal', input_shape=(12,1293, 1)),\n#  tf.keras.layers.RandomRotation(0.3),\n#])\n\nchrom_model = models.Sequential()\nchrom_model.add(layers.Conv2D(30, kernel_size=(7, 7), activation='relu', input_shape=(12, 1293, 1), padding='same'))\n#chrom_model.add(data_augment)\nchrom_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\n#chrom_model.add(layers.BatchNormalization())\nchrom_model.add(layers.MaxPooling2D())\nchrom_model.add(layers.Dropout(0.4))\n\nchrom_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\nchrom_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\nchrom_model.add(layers.MaxPooling2D())\n\nchrom_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\nchrom_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\n#chrom_model.add(layers.MaxPooling2D())\n\n\n#chrom_model.summary()\nchrom_model.add(layers.Flatten())\nchrom_model.add(layers.Dense(60, activation='relu'))\n#chrom_model.add(layers.Dropout(0.4))\nchrom_model.add(layers.Dense(8))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T16:54:07.085198Z","iopub.execute_input":"2023-12-14T16:54:07.085614Z","iopub.status.idle":"2023-12-14T16:54:07.208360Z","shell.execute_reply.started":"2023-12-14T16:54:07.085581Z","shell.execute_reply":"2023-12-14T16:54:07.207547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\nchrom_model.compile(optimizer=opt,\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nchrom_hist = chrom_model.fit(chrom_train, train_labels, batch_size = 50, epochs=60, \n                    validation_data=(chrom_val, val_labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot training vs validation loss and accuracy\nacc = chrom_hist.history['accuracy']\nval_acc = chrom_hist.history['val_accuracy']\n\nloss = chrom_hist.history['loss']\nval_loss = chrom_hist.history['val_loss']\n\nepochs = 60\n\nplt.subplot(1, 2, 1)\nplt.plot(range(epochs), acc)\nplt.plot(range(epochs), val_acc)\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.title('Training vs Validation Accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\n\nplt.subplot(1, 2, 2)\nplt.plot(range(epochs), loss)\nplt.plot(range(epochs), val_loss)\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.title('Training vs Validation Loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T16:00:21.871150Z","iopub.execute_input":"2023-12-14T16:00:21.872011Z","iopub.status.idle":"2023-12-14T16:00:22.411601Z","shell.execute_reply.started":"2023-12-14T16:00:21.871980Z","shell.execute_reply":"2023-12-14T16:00:22.410773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trial 2: MFCC spectrogram feature extraction\nmfcc_train = np.empty([1,20, 1293])\nmfcc_val = np.empty([1,20, 1293])\nmfcc_test = np.empty([1,20, 1293])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:05:36.746085Z","iopub.execute_input":"2023-12-14T15:05:36.747145Z","iopub.status.idle":"2023-12-14T15:05:36.752097Z","shell.execute_reply.started":"2023-12-14T15:05:36.747106Z","shell.execute_reply":"2023-12-14T15:05:36.751073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mfcc_extraction(X,track_ids):\n    for i in track_ids:\n        filepath = get_audio_path('/kaggle/input/fma-audio/fma_small', i)\n        x, sr = librosa.load(filepath)\n        mfcc = librosa.feature.mfcc(y=x, sr=sr)\n        a, b = mfcc.shape\n        #padding the feature arrays to make sure all arrays are the same size\n        if (b < 1293):\n            if (1293 - b) % 2 == 0:\n                mfcc = np.pad(mfcc, ((0,0),(int((1293-b)/2),int((1293-b)/2))), 'edge')\n            else:\n                mfcc = np.pad(mfcc, ((0,0),(int((1293-b)/2),int((1293-b)/2)+1)), 'edge')\n        X = np.append(X, [mfcc], axis = 0)\n    return X\n\n\n#MFCC feature extraction\nmfcc_train = mfcc_extraction(mfcc_train,train_track_ids)\nmfcc_val = mfcc_extraction(mfcc_val,val_track_ids)\nmfcc_test = mfcc_extraction(mfcc_test,test_track_ids)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:05:38.182808Z","iopub.execute_input":"2023-12-14T15:05:38.183946Z","iopub.status.idle":"2023-12-14T15:29:27.241834Z","shell.execute_reply.started":"2023-12-14T15:05:38.183900Z","shell.execute_reply":"2023-12-14T15:29:27.240346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the first feature array in each data subset is an extra \"arbitrary\" feature array \n# We remove this extra feature array here\nmfcc_train = np.delete(mfcc_train, 0, 0)\nmfcc_val = np.delete(mfcc_val, 0, 0)\nmfcc_test = np.delete(mfcc_test, 0, 0)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:29:27.244968Z","iopub.execute_input":"2023-12-14T15:29:27.245927Z","iopub.status.idle":"2023-12-14T15:29:27.631050Z","shell.execute_reply.started":"2023-12-14T15:29:27.245877Z","shell.execute_reply":"2023-12-14T15:29:27.630241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(x):\n    maxim = np.max(x)\n    return x/maxim\nmfcc_train = normalize(mfcc_train)\nmfcc_val = normalize(mfcc_val)\nmfcc_test = normalize(mfcc_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T15:29:27.632149Z","iopub.execute_input":"2023-12-14T15:29:27.632462Z","iopub.status.idle":"2023-12-14T15:29:28.017940Z","shell.execute_reply.started":"2023-12-14T15:29:27.632415Z","shell.execute_reply":"2023-12-14T15:29:28.016879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CNN model for MFCCs\n#data_augment = tf.keras.Sequential([\n # tf.keras.layers.RandomFlip('horizontal', input_shape=(20,1293, 1)),\n  #tf.keras.layers.RandomRotation(0.3),\n#])\nmfcc_model = models.Sequential()\nmfcc_model.add(layers.Conv2D(30, kernel_size=(7, 7), activation='relu', input_shape=(20, 1293, 1), padding='same'))\n#mfcc_model.add(data_augment)\nmfcc_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\n#mfcc_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\n#chrom_model.add(layers.BatchNormalization())\nmfcc_model.add(layers.MaxPooling2D())\nmfcc_model.add(layers.Dropout(0.4))\n\nmfcc_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\nmfcc_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\nmfcc_model.add(layers.MaxPooling2D())\n\nmfcc_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\nmfcc_model.add(layers.Conv2D(60, kernel_size=(7, 7), activation='relu', padding='same'))\n\n#mfcc_model.summary()\nmfcc_model.add(layers.Flatten())\nmfcc_model.add(layers.Dense(60, activation='relu'))\nmfcc_model.add(layers.Dense(8))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T16:59:52.377528Z","iopub.execute_input":"2023-12-14T16:59:52.377885Z","iopub.status.idle":"2023-12-14T16:59:52.502279Z","shell.execute_reply.started":"2023-12-14T16:59:52.377857Z","shell.execute_reply":"2023-12-14T16:59:52.501440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.00005)\nmfcc_model.compile(optimizer=opt,\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmfcc_hist = mfcc_model.fit(mfcc_train, train_labels, batch_size=30, epochs=50, \n                    validation_data=(mfcc_val, val_labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = mfcc_hist.history['accuracy']\nval_acc = mfcc_hist.history['val_accuracy']\n\nloss = mfcc_hist.history['loss']\nval_loss = mfcc_hist.history['val_loss']\n\nepochs = 50\n\nplt.subplot(1, 2, 1)\nplt.plot(range(epochs), acc)\nplt.plot(range(epochs), val_acc)\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.title('Training vs Validation Accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\n\nplt.subplot(1, 2, 2)\nplt.plot(range(epochs), loss)\nplt.plot(range(epochs), val_loss)\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.title('Training vs Validation Loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T16:34:44.564365Z","iopub.execute_input":"2023-12-14T16:34:44.565274Z","iopub.status.idle":"2023-12-14T16:34:45.107906Z","shell.execute_reply.started":"2023-12-14T16:34:44.565210Z","shell.execute_reply":"2023-12-14T16:34:45.106907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Baseline Linear SVM implementation\n\n#First, we extract spectral flatness features from music files\nspec_flat_train = np.empty([1,1293])\nspec_flat_val = np.empty([1,1293])\nspec_flat_test = np.empty([1,1293])\n\ndef flat_extraction(X,track_ids):\n    for i in track_ids:\n        filepath = get_audio_path('/kaggle/input/fma-audio/fma_small', i)\n        x, sr = librosa.load(filepath)\n        flat = librosa.feature.spectral_flatness(y=x)\n        a, b = flat.shape\n        #padding the feature arrays to make sure all arrays are the same size\n        if (b < 1293):\n            if (1293 - b) % 2 == 0:\n                flat = np.pad(flat, ((0,0),(int((1293-b)/2),int((1293-b)/2))), 'edge')\n            else:\n                flat = np.pad(flat, ((0,0),(int((1293-b)/2),int((1293-b)/2)+1)), 'edge')\n        X = np.append(X, flat, axis = 0)\n    return X\n\n# Spectral Flatness feature extraction\nspec_flat_train = flat_extraction(spec_flat_train,train_track_ids)\nspec_flat_val = flat_extraction(spec_flat_val,val_track_ids)\nspec_flat_test = flat_extraction(spec_flat_test,test_track_ids)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T15:36:10.047562Z","iopub.execute_input":"2023-12-12T15:36:10.048013Z","iopub.status.idle":"2023-12-12T15:45:20.264339Z","shell.execute_reply.started":"2023-12-12T15:36:10.047975Z","shell.execute_reply":"2023-12-12T15:45:20.263423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the first feature array in each data subset is an extra \"arbitrary\" feature array \n# We remove this extra feature array here\nspec_flat_train = np.delete(spec_flat_train, 0, 0)\nspec_flat_val = np.delete(spec_flat_val, 0, 0)\nspec_flat_test = np.delete(spec_flat_test, 0, 0)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T15:50:54.888855Z","iopub.execute_input":"2023-12-12T15:50:54.889573Z","iopub.status.idle":"2023-12-12T15:50:54.906323Z","shell.execute_reply.started":"2023-12-12T15:50:54.889542Z","shell.execute_reply":"2023-12-12T15:50:54.905567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build and train Linear SVM\nclassifier = svm.SVC(decision_function_shape='ovo')\nclassifier.fit(spec_flat_train, train_labels)\n\n#Output test accuracy and validation accuracy\nprint(\"Baseline SVM Test Accuracy: \" + str(classifier.score(spec_flat_test, test_labels)))\nprint(\"Baseline SVM Validation Accuracy: \"+ str(classifier.score(spec_flat_val, val_labels)))","metadata":{"execution":{"iopub.status.busy":"2023-12-12T15:58:27.922523Z","iopub.execute_input":"2023-12-12T15:58:27.923235Z","iopub.status.idle":"2023-12-12T15:58:37.849340Z","shell.execute_reply.started":"2023-12-12T15:58:27.923201Z","shell.execute_reply":"2023-12-12T15:58:37.848290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing models\n#t_score, acc = mfcc_model.evaluate(mfcc_test, test_labels)\n#print('MFCC Test accuracy:', acc)\n\n#t_score, acc = chrom_model.evaluate(chrom_test, test_labels)\n#print('Chroma Test accuracy:', acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}